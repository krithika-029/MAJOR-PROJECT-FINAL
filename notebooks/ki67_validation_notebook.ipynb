{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1523f866",
   "metadata": {},
   "source": [
    "# Ki-67 Model Validation - Get Your REAL Accuracy!\n",
    "\n",
    "This notebook will give you the **actual F1 accuracy** of your trained model.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload your checkpoint: `ki67-point-epoch=68-val_peak_f1_avg=0.8503.ckpt` to the `/content/` folder\n",
    "2. Make sure your `BCData.zip` is in your Google Drive (MyDrive folder)\n",
    "3. Run all cells below\n",
    "4. Get your REAL accuracy score!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153670f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and extract dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Unzip BCData.zip from Google Drive\n",
    "!unzip -q \"/content/drive/MyDrive/BCData.zip\" -d \"/content/\"\n",
    "print(\"‚úÖ Dataset extracted to /content/BCData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c47bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q segmentation-models-pytorch albumentations h5py opencv-python-headless pytorch-lightning scipy scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import h5py\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial.distance import cdist\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26794bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy classes from your training script\n",
    "class ImprovedPointHeatmapGenerator:\n",
    "    def __init__(self, sigma=8.0):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def generate_heatmap(self, points, image_shape=(640, 640)):\n",
    "        if len(points) == 0:\n",
    "            return np.zeros(image_shape, dtype=np.float32)\n",
    "        \n",
    "        heatmap = np.zeros(image_shape, dtype=np.float32)\n",
    "        kernel_size = int(6 * self.sigma + 1)\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        \n",
    "        x = np.arange(0, kernel_size)\n",
    "        y = x[:, np.newaxis]\n",
    "        x0 = y0 = kernel_size // 2\n",
    "        \n",
    "        gaussian = np.exp(-((x - x0) ** 2 + (y - y0) ** 2) / (2 * self.sigma ** 2))\n",
    "        gaussian = gaussian / gaussian.max()\n",
    "        \n",
    "        for point in points:\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            x_min = max(0, x - kernel_size // 2)\n",
    "            x_max = min(image_shape[1], x + kernel_size // 2 + 1)\n",
    "            y_min = max(0, y - kernel_size // 2)\n",
    "            y_max = min(image_shape[0], y + kernel_size // 2 + 1)\n",
    "            \n",
    "            k_x_min = max(0, kernel_size // 2 - x)\n",
    "            k_x_max = min(kernel_size, kernel_size // 2 + (image_shape[1] - x))\n",
    "            k_y_min = max(0, kernel_size // 2 - y)\n",
    "            k_y_max = min(kernel_size, kernel_size // 2 + (image_shape[0] - y))\n",
    "            \n",
    "            heatmap[y_min:y_max, x_min:x_max] = np.maximum(\n",
    "                heatmap[y_min:y_max, x_min:x_max],\n",
    "                gaussian[k_y_min:k_y_max, k_x_min:k_x_max]\n",
    "            )\n",
    "        \n",
    "        return heatmap\n",
    "\n",
    "class Ki67PointDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotation_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.transform = transform\n",
    "        self.heatmap_generator = ImprovedPointHeatmapGenerator(sigma=8.0)\n",
    "        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def load_points_from_h5(self, h5_path):\n",
    "        try:\n",
    "            with h5py.File(h5_path, 'r') as f:\n",
    "                if 'coordinates' in f:\n",
    "                    return f['coordinates'][:]\n",
    "        except:\n",
    "            pass\n",
    "        return np.array([])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        pos_h5 = os.path.join(self.annotation_dir, 'positive', f\"{base_name}.h5\")\n",
    "        neg_h5 = os.path.join(self.annotation_dir, 'negative', f\"{base_name}.h5\")\n",
    "        \n",
    "        pos_points = self.load_points_from_h5(pos_h5)\n",
    "        neg_points = self.load_points_from_h5(neg_h5)\n",
    "        \n",
    "        pos_heatmap = self.heatmap_generator.generate_heatmap(pos_points, image.shape[:2])\n",
    "        neg_heatmap = self.heatmap_generator.generate_heatmap(neg_points, image.shape[:2])\n",
    "        heatmaps = np.stack([pos_heatmap, neg_heatmap], axis=0)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=heatmaps.transpose(1, 2, 0))\n",
    "            image = transformed['image']\n",
    "            heatmaps = transformed['mask'].permute(2, 0, 1).float()\n",
    "        else:\n",
    "            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
    "            heatmaps = torch.from_numpy(heatmaps).float()\n",
    "        \n",
    "        return image, heatmaps, img_name\n",
    "\n",
    "class ImprovedKi67PointDetectionModel(pl.LightningModule):\n",
    "    def __init__(self, encoder_name='efficientnet-b3', learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = smp.Unet(encoder_name=encoder_name, encoder_weights='imagenet', in_channels=3, classes=2, activation=None)\n",
    "        self.criterion = ImprovedHeatmapLoss(pos_weight=10.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ImprovedHeatmapLoss(nn.Module):\n",
    "    def __init__(self, pos_weight=10.0):\n",
    "        super().__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight]), reduction='mean')\n",
    "    \n",
    "    def dice_loss(self, pred, target, smooth=1e-6):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        intersection = (pred * target).sum(dim=(2, 3))\n",
    "        union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n",
    "        dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "        return 1.0 - dice.mean()\n",
    "    \n",
    "    def focal_loss(self, pred, target, alpha=0.25, gamma=2.0):\n",
    "        bce_loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, target, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal_loss = alpha * (1 - pt) ** gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        focal = self.focal_loss(pred, target)\n",
    "        total_loss = 0.4 * bce_loss + 0.4 * dice + 0.2 * focal\n",
    "        return total_loss, {'bce': bce_loss.item(), 'dice': dice.item(), 'focal': focal.item()}\n",
    "\n",
    "print(\"‚úÖ Classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeeefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main validation function\n",
    "def get_actual_accuracy(checkpoint_path='/content/ki67-point-epoch=68-val_peak_f1_avg=0.8503.ckpt',\n",
    "                       data_path='/content/BCData'):\n",
    "    \"\"\"\n",
    "    Get the REAL F1 accuracy of your trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç Getting REAL Model Accuracy...\")\n",
    "    print(f\"Model: {checkpoint_path}\")\n",
    "    print(f\"Data: {data_path}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check files exist\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"‚ùå Model not found: {checkpoint_path}\")\n",
    "        return None\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"‚ùå Data not found: {data_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model = ImprovedKi67PointDetectionModel.load_from_checkpoint(checkpoint_path)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"‚úì Model loaded on {device}\")\n",
    "    \n",
    "    # Create validation dataset\n",
    "    val_transform = A.Compose([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    val_dataset = Ki67PointDataset(\n",
    "        image_dir=os.path.join(data_path, 'images/validation'),\n",
    "        annotation_dir=os.path.join(data_path, 'annotations/validation'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"‚úì Validation dataset: {len(val_dataset)} images\")\n",
    "    \n",
    "    # Run validation\n",
    "    print(\"Running validation...\")\n",
    "    all_pred = []\n",
    "    all_target = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, heatmaps, names in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            pred_heatmaps = torch.sigmoid(outputs)\n",
    "            \n",
    "            all_pred.append(pred_heatmaps.cpu())\n",
    "            all_target.append(heatmaps.cpu())\n",
    "    \n",
    "    all_pred = torch.cat(all_pred)\n",
    "    all_target = torch.cat(all_target)\n",
    "    \n",
    "    print(f\"‚úì Processed {len(all_pred)} images\")\n",
    "    \n",
    "    # Compute peak-based F1 (the real metric)\n",
    "    total_tp_pos, total_fp_pos, total_fn_pos = 0, 0, 0\n",
    "    total_tp_neg, total_fp_neg, total_fn_neg = 0, 0, 0\n",
    "    \n",
    "    for i in range(len(all_pred)):\n",
    "        pred_pos = all_pred[i, 0].float().numpy()\n",
    "        pred_neg = all_pred[i, 1].float().numpy()\n",
    "        target_pos = all_target[i, 0].float().numpy()\n",
    "        target_neg = all_target[i, 1].float().numpy()\n",
    "        \n",
    "        # Positive cells\n",
    "        pred_peaks_pos = peak_local_max(pred_pos, threshold_abs=0.3, min_distance=10)\n",
    "        target_peaks_pos = peak_local_max(target_pos, threshold_abs=0.2, min_distance=10)\n",
    "        \n",
    "        if len(pred_peaks_pos) > 0 and len(target_peaks_pos) > 0:\n",
    "            distances = cdist(pred_peaks_pos, target_peaks_pos)\n",
    "            matches = (distances < 10).any(axis=1)\n",
    "            total_tp_pos += matches.sum()\n",
    "            total_fp_pos += len(pred_peaks_pos) - matches.sum()\n",
    "            total_fn_pos += len(target_peaks_pos) - matches.sum()\n",
    "        else:\n",
    "            total_fp_pos += len(pred_peaks_pos)\n",
    "            total_fn_pos += len(target_peaks_pos)\n",
    "        \n",
    "        # Negative cells\n",
    "        pred_peaks_neg = peak_local_max(pred_neg, threshold_abs=0.3, min_distance=10)\n",
    "        target_peaks_neg = peak_local_max(target_neg, threshold_abs=0.2, min_distance=10)\n",
    "        \n",
    "        if len(pred_peaks_neg) > 0 and len(target_peaks_neg) > 0:\n",
    "            distances = cdist(pred_peaks_neg, target_peaks_neg)\n",
    "            matches = (distances < 10).any(axis=1)\n",
    "            total_tp_neg += matches.sum()\n",
    "            total_fp_neg += len(pred_peaks_neg) - matches.sum()\n",
    "            total_fn_neg += len(target_peaks_neg) - matches.sum()\n",
    "        else:\n",
    "            total_fp_neg += len(pred_peaks_neg)\n",
    "            total_fn_neg += len(target_peaks_neg)\n",
    "    \n",
    "    # Calculate F1 scores\n",
    "    f1_pos = 2 * total_tp_pos / (2 * total_tp_pos + total_fp_pos + total_fn_pos + 1e-6)\n",
    "    f1_neg = 2 * total_tp_neg / (2 * total_tp_neg + total_fp_neg + total_fn_neg + 1e-6)\n",
    "    f1_avg = (f1_pos + f1_neg) / 2\n",
    "    \n",
    "    # Results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéØ ACTUAL MODEL ACCURACY RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Peak-based F1 Score (Positive): {f1_pos:.4f}\")\n",
    "    print(f\"Peak-based F1 Score (Negative): {f1_neg:.4f}\")\n",
    "    print(f\"AVERAGE F1 SCORE: {f1_avg:.4f}\")\n",
    "    print(f\"ACCURACY: {f1_avg*100:.2f}%\")\n",
    "    print()\n",
    "    print(\"INTERPRETATION:\")\n",
    "    if f1_avg >= 0.95:\n",
    "        print(\"üéâ EXCELLENT: 95%+ accuracy - World-class performance!\")\n",
    "    elif f1_avg >= 0.90:\n",
    "        print(\"‚úÖ OUTSTANDING: 90%+ accuracy - Clinical gold standard!\")\n",
    "    elif f1_avg >= 0.85:\n",
    "        print(\"üëç VERY GOOD: 85%+ accuracy - Better than most published methods!\")\n",
    "    elif f1_avg >= 0.80:\n",
    "        print(\"üëå GOOD: 80%+ accuracy - Clinical grade performance!\")\n",
    "    elif f1_avg >= 0.70:\n",
    "        print(\"‚ö†Ô∏è FAIR: 70%+ accuracy - Needs improvement\")\n",
    "    else:\n",
    "        print(\"‚ùå POOR: <70% accuracy - Retrain needed\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return {\n",
    "        'f1_avg': f1_avg,\n",
    "        'f1_pos': f1_pos,\n",
    "        'f1_neg': f1_neg,\n",
    "        'accuracy_percent': f1_avg * 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN VALIDATION - This is the main cell to run!\n",
    "print(\"üéØ Ki-67 Model Validation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get your REAL accuracy!\n",
    "results = get_actual_accuracy()\n",
    "\n",
    "if results:\n",
    "    print(\"\\n‚úÖ Validation Complete!\")\n",
    "    print(f\"Final F1 Score: {results['f1_avg']:.4f}\")\n",
    "    print(f\"Accuracy: {results['accuracy_percent']:.1f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Validation failed - check your paths!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
